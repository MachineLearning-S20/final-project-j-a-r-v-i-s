{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sO9kjEdrijYM",
    "outputId": "9fad9cb3-c35d-4985-ccc2-7acb6cb60943"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import datetime \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io \n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage import img_as_ubyte\n",
    "import os\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfWyMm64i6Kd"
   },
   "outputs": [],
   "source": [
    "class ASL_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "      \n",
    "        X_2d = []\n",
    "        for i in X:\n",
    "              X_2d.append(i.reshape(1, 50, 50))\n",
    "        X_2d = np.array(X_2d)\n",
    "    \n",
    "        # Convert data & labels from numpy to PyTorch format\n",
    "        data = torch.FloatTensor(X_2d)\n",
    "        #data = data.permute(0,3,1,2)        \n",
    "        labels = torch.LongTensor(y)        \n",
    "\n",
    "        # Store data as part of the class        \n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "      \n",
    "        # Calculate and return the number of samples in the dataset\n",
    "        return(len(self.labels))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "921mDl_VldgI"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/justuser/sign-language-classifier-convnet-with-pytorch\n",
    "class Network(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 15, 3) #15 or 20\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(15, 20, 3) #20 or 30\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        \n",
    "        self.fc3 = nn.Linear(20 * 9 * 9, 270) \n",
    "        self.fc4 = nn.Linear(270, 9) \n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "                \n",
    "        x = x.view(-1, 20 * 9 * 9) \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        return self.softmax(x)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wm2nRWK6eP9q"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     LoadMNIST()\n",
    "# Inputs:       N/A\n",
    "# Output:       X   - MNIST images\n",
    "#               y   - MNIST labels\n",
    "# Description:  This function loads the MNIST training and testing images. We \n",
    "#               will combine both sets in order to create one big dataset, and\n",
    "#               then reduce the size as to not overfit our model with the\n",
    "#               MNIST data. The images for letters C, G, H are different \n",
    "#               formats so we will discard of these images.\n",
    "###############################################################################\n",
    "\n",
    "def LoadMNIST():\n",
    "\n",
    "    # Load data\n",
    "    data_raw = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "    test_data_raw = test = pd.read_csv(\"sign_mnist_test.csv\")\n",
    "\n",
    "    # Break up data and labels\n",
    "    labels = data_raw['label']\n",
    "    data_raw.drop('label', axis=1, inplace=True)\n",
    "    labels_test = test_data_raw['label']\n",
    "    test_data_raw.drop('label', axis=1, inplace=True)\n",
    "\n",
    "    # Normalize data\n",
    "    data_full = data_raw.values/255\n",
    "    labels_full = labels.values\n",
    "    test_data_full = test_data_raw.values/255 \n",
    "    labels_test_full = labels_test.values \n",
    "\n",
    "    # Concatenate training and test set\n",
    "    X_MNIST_full = np.concatenate((data_full, test_data_full))\n",
    "    y_MNIST_full = np.concatenate((labels_full, labels_test_full))\n",
    "\n",
    "    # Get rid of unused letters and the letters c, g, and h\n",
    "    X_MNIST = []\n",
    "    y_MNIST = []\n",
    "    for i in range(len(y_MNIST_full)):\n",
    "        if (y_MNIST_full[i] <= 8 and y_MNIST_full[i] != 2 and y_MNIST_full[i] != 6 and y_MNIST_full[i] != 7):\n",
    "            X_MNIST.append(X_MNIST_full[i])\n",
    "            y_MNIST.append(y_MNIST_full[i])\n",
    "    X_MNIST = np.asarray(X_MNIST)\n",
    "    y_MNIST = np.asarray(y_MNIST)\n",
    "\n",
    "    # Reshape data to 50x50\n",
    "    X_MNIST_50 = []\n",
    "    for i in range (len(X_MNIST)):\n",
    "        img_flat_orig = X_MNIST[i];\n",
    "        img_2d_orig = img_flat_orig.reshape(28, 28)\n",
    "        img_2d_new = cv2.resize(img_2d_orig, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
    "        img_1d_new = img_2d_new.flatten()\n",
    "        X_MNIST_50.append(img_1d_new)\n",
    "    X_MNIST_50 = np.asarray(X_MNIST_50)\n",
    "\n",
    "    # Store indices for each image and order them by letter\n",
    "    idx = np.ones((9,1457))*-1 \n",
    "    for i in range(len(y_MNIST)):\n",
    "        curr_let = y_MNIST[i]\n",
    "        curr_row = idx[curr_let]\n",
    "        unique_elements, counts_elements = np.unique(curr_row, return_counts=True)\n",
    "        next_idx = len(unique_elements) - 1\n",
    "        idx[curr_let][next_idx] = i\n",
    "\n",
    "    # Randomly choose N number of images for each letter\n",
    "    X_MNIST_reduced = []\n",
    "    y_MNIST_reduced = []\n",
    "    for i in range(idx.shape[0]):\n",
    "        if (i == 2 or i == 6 or i == 7):\n",
    "            continue\n",
    "        for j in range(1000): # <----Change here to get reduced MNIST dataset size\n",
    "            ran_num = random.randint(0,idx.shape[1]-1)\n",
    "            while (idx[i][ran_num] == -1):\n",
    "                ran_num = random.randint(0,idx.shape[1]-1)\n",
    "            X_MNIST_reduced.append(X_MNIST_50[idx[i][ran_num].astype(int)])\n",
    "            y_MNIST_reduced.append(y_MNIST[idx[i][ran_num].astype(int)])\n",
    "    X_MNIST_reduced = np.asarray(X_MNIST_reduced)\n",
    "    y_MNIST_reduced = np.asarray(y_MNIST_reduced)\n",
    "\n",
    "    return X_MNIST_reduced, y_MNIST_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myZivVmlA898"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     Multiple Data Augmentation Functions\n",
    "# Inputs:       N/A\n",
    "# Output:       N/A\n",
    "# Description:  These functions will perform a variety of data aumgentation \n",
    "#               functions, including rotation, flipping, adding noise, adding \n",
    "#               blur, and warp shifting.\n",
    "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
    "#               numpy-opencv-and-skimage-ef027e9898da\n",
    "###############################################################################\n",
    "def anticlockwise_rotation(image):\n",
    "    angle= random.randint(0,8)\n",
    "    return rotate(image, angle)\n",
    "\n",
    "def clockwise_rotation(image):\n",
    "    angle= random.randint(0,8)\n",
    "    return rotate(image, -angle)\n",
    "\n",
    "#def h_flip(image):\n",
    "    return  np.fliplr(image)\n",
    "\n",
    "#def v_flip(image):\n",
    "    #return np.flipud(image)\n",
    "\n",
    "def add_noise(image):\n",
    "    return random_noise(image)\n",
    "\n",
    "def blur_image(image):\n",
    "    return cv2.GaussianBlur(img, (9,9),0)\n",
    "\n",
    "def warp_shift(image): \n",
    "    transform = AffineTransform(translation=(0,40)) \n",
    "    warp_image = warp(image, transform, mode=\"wrap\")\n",
    "    return warp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uz-XSJvloM_2"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     CreateImages()\n",
    "# Inputs:       Letter - Chooses which letter to data augment\n",
    "#               X     - Input images\n",
    "#               y     - Output vectors\n",
    "# Output:       X_new - Data augmented images\n",
    "#               y_new - Data augmented labels\n",
    "# Description:  This function performs data augmentation for letters G and \n",
    "#               H. It will also perform minor data augmentation for the whole\n",
    "#               dataset to increase the size and type of images we train our\n",
    "#               model with.\n",
    "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
    "#               numpy-opencv-and-skimage-ef027e9898da\n",
    "###############################################################################\n",
    "\n",
    "def CreateImages(letter, num_imgs, X, y):\n",
    "  \n",
    "    transformations = {'rotate anticlockwise': anticlockwise_rotation,\n",
    "                          'rotate clockwise': clockwise_rotation,\n",
    "                          #'horizontal flip': h_flip, \n",
    "                          #'vertical flip': v_flip,\n",
    "                          'warp shift': warp_shift,\n",
    "                          'adding noise': add_noise}\n",
    "\n",
    "    index = []\n",
    "    if (letter == \"G\"):\n",
    "\n",
    "        # Find every index of G images\n",
    "        for i in range(len(y)):\n",
    "            if(y[i] == 6):\n",
    "                index.append(i)\n",
    "\n",
    "    elif (letter == \"H\"):\n",
    "\n",
    "        # Find every index of H images\n",
    "        for i in range(len(y)):\n",
    "            if(y[i] == 7):\n",
    "                index.append(i)\n",
    "    else:\n",
    "\n",
    "        # Use all indices\n",
    "        for i in range(len(y)):\n",
    "            index.append(i)\n",
    "   \n",
    "    X_new = []\n",
    "    y_new = []\n",
    "\n",
    "    for i in range(1, num_imgs + 1):\n",
    "        idx = random.choice(index)\n",
    "        y_new.append(y[idx])\n",
    "        original_image = X[idx].reshape(50,50)\n",
    "        transformed_image=None\n",
    "        n = 0\n",
    "        transformation_count = random.randint(1, len(transformations))\n",
    "        while n <= transformation_count:\n",
    "            key = random.choice(list(transformations))\n",
    "            transformed_image = transformations[key](original_image)  \n",
    "            n = n + 1    \n",
    "        trans_img = transformed_image.flatten()\n",
    "        X_new.append(trans_img);\n",
    "\n",
    "    return X_new, y_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8Xpr9SGPrF4"
   },
   "outputs": [],
   "source": [
    "def AddC():\n",
    "    C_data = np.load('data.npy')\n",
    "    C_labels = np.load('labels.npy')\n",
    "    C_labels.resize(709,1)\n",
    "\n",
    "    y_C = []\n",
    "    for i in range(len(C_labels)):\n",
    "            y_C.append(2)\n",
    "    y_C = np.asarray(y_C)\n",
    "\n",
    "    # Normalize and format data\n",
    "    X_C = []\n",
    "    for i in range(C_data.shape[0]):\n",
    "        img = C_data[i]\n",
    "        img_r = cv2.resize(img, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
    "        img_g = rgb2gray(img_r)\n",
    "        img_1d = img_g.flatten()\n",
    "        X_C.append(img_1d)\n",
    "    X_C = np.asarray(X_C)\n",
    "\n",
    "    return X_C, y_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ2FAZwqj4X0"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     DataAug()\n",
    "# Inputs:       X    - Input images\n",
    "#               y    - Output vectors\n",
    "# Output:       X_DA - Data augmented images\n",
    "#               y_DA - Data augmented labels\n",
    "# Description:  This function will use data augmentation to increase the size\n",
    "#               of our data and make our training set more proportional.\n",
    "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
    "#               numpy-opencv-and-skimage-ef027e9898da\n",
    "###############################################################################\n",
    "\n",
    "def DataAug(X, y):\n",
    "  \n",
    "    ###################### Data Augmentation with G ###########################\n",
    "    # Create 800 more images of letter G\n",
    "    X_G, y_G = CreateImages(\"G\", 700, X, y)\n",
    "\n",
    "    ###################### Data Augmentation with H ###########################\n",
    "    # Create 800 more images of letter H\n",
    "    X_H, y_H = CreateImages(\"H\", 700, X, y)\n",
    "      \n",
    "    ##################### Data Augmentation with All ##########################\n",
    "    # Create 1000 more images of all letters\n",
    "    X_all, y_all = CreateImages(\"All\", 1000, X, y)\n",
    "\n",
    "    X_DA = np.concatenate((X_G, X_H, X_all))\n",
    "    y_DA = np.concatenate((y_G, y_H, y_all))\n",
    "\n",
    "    return X_DA, y_DA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdCqlQKj27NA"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     validate()\n",
    "# Inputs:       model        - model\n",
    "#               train_loader - training set dataloader\n",
    "#               val_loader   - validation set dataloader\n",
    "# Output:       N/A\n",
    "# Description:  This function will perform the validation of our\n",
    "#               trained model. Taken from Lecture 22 by Dr. Silva.\n",
    "###############################################################################\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]  \n",
    "                correct += int((predicted == labels).sum()) \n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qCOMXSRWsyu"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function:     train()\n",
    "# Inputs:       X - array of images in Nx100x100x3 format\n",
    "#               y - array of output charcters for images in Nx1 format \n",
    "# Output:       N/A\n",
    "# Description:  This function trains our CNN model with the dataset inputted \n",
    "#               through X and y. This fucntion will combine X and y with the\n",
    "#               MNIST hand gesture recognition dataset from Kaggle, and \n",
    "#               additional images of the letter C, to train a model compirsed\n",
    "#               of 3 convolutional layers and two linear layers, with\n",
    "#               dropout and maxpooling.\n",
    "###############################################################################\n",
    "\n",
    "def train(X, y):\n",
    "    ################# Section 1: Preprocessing/Splitting ######################\n",
    "    # Our preprocessing pipeline includes:\n",
    "    #          - Resizing images to 50x50\n",
    "    #          - Grayscaling images\n",
    "    #          - Flattening images to a 1D vecotr\n",
    "    #          - Converting the labels from characters to numbers\n",
    "    # We resize the image to half its original size to limit the amount of \n",
    "    # features inputted into our model. Grayscaling also diminshes the images \n",
    "    # to only 1 channel and will normalize our values between 0 and 1 for us. \n",
    "    # We flatten the images to 1D in order to more easily combine it with our \n",
    "    # other dataset. We will als0 split this data into training and validation \n",
    "    # since we will want to run a test on just this data to see how our model \n",
    "    # performs.\n",
    "    ###########################################################################\n",
    "    # Preprocessing\n",
    "    X_norm = []\n",
    "    for i in range(X.shape[0]):\n",
    "        img = X[i]\n",
    "        img_r = cv2.resize(img, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
    "        img_g = rgb2gray(img_r)\n",
    "        img_1d = img_g.flatten()\n",
    "        X_norm.append(img_1d)\n",
    "    X_norm = np.asarray(X_norm)\n",
    "\n",
    "    # Convert characters to numbers\n",
    "    y = np.squeeze(y)\n",
    "    ulabels = np.unique(y)\n",
    "    y_num = np.zeros(len(y))\n",
    "    for i in range(len(ulabels)):\n",
    "        y_num[y == ulabels[i]] = i\n",
    "\n",
    "    # Splitting\n",
    "    X_train_class, X_val_class, y_train_class, y_val_class = train_test_split(\n",
    "          X_norm, y_num, test_size = 0.2, random_state = 4) \n",
    "\n",
    "    ################## Section 2: Loading Other DatasetS #######################\n",
    "    # We will now add our addition MNIST dataset from Kaggle, and additional \n",
    "    # photos taken of the letter C. \n",
    "    # The images from Kaggle are in a Nx784 array. The additional images of the \n",
    "    # letter C are in the same format as the input data. \n",
    "    # Link: https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "    ###########################################################################\n",
    "\n",
    "    X_MNIST, y_MNIST = LoadMNIST()\n",
    "\n",
    "    X_train_MNIST, X_val_MNIST, y_train_MNIST, y_val_MNIST = train_test_split(\n",
    "          X_MNIST, y_MNIST, test_size = 0.2, random_state = 4) \n",
    "    \n",
    "    X_C, y_C = AddC();\n",
    "\n",
    "    ##################### Section 3: Combining Datasets #######################\n",
    "    # We will now combine datasets to get our total training and validation \n",
    "    # sets.\n",
    "    ###########################################################################\n",
    "\n",
    "    X_train_comb = np.concatenate((X_train_class, X_train_MNIST, X_C))\n",
    "    y_train_comb = np.concatenate((y_train_class, y_train_MNIST, y_C))\n",
    "    X_val_comb = np.concatenate((X_val_class, X_val_MNIST))\n",
    "    y_val_comb = np.concatenate((y_val_class, y_val_MNIST))\n",
    "\n",
    "    ##################### Section 4: Data Augmentation ########################\n",
    "    # We will see that when we combine our class data and our MNIST data, we \n",
    "    # have a unproportional amount for each letter. Namely, we don't have any G \n",
    "    # and H data from MNIST. This is because the hand gestures of these letters \n",
    "    # do no match how our class data is. We will use data augmentation to \n",
    "    # increase the size for these letters, and to also add more images for\n",
    "    # every letter to increase the size of our dataset and to \n",
    "    ###########################################################################\n",
    "\n",
    "    X_DA, y_DA = DataAug(X_train_comb, y_train_comb)\n",
    "\n",
    "    X_train_comb = np.concatenate((X_train_comb, X_DA))\n",
    "    y_train_comb = np.concatenate((y_train_comb, y_DA))\n",
    "\n",
    "    # Print the spread of our training data\n",
    "    plt.figure(figsize = (10,5))\n",
    "    sns.countplot(x = y_train_comb);\n",
    "    plt.show()\n",
    "\n",
    "    ######################## Section 5: Training ##############################\n",
    "    # We will now train our model with our combined training dataset. We are \n",
    "    # a custom dataset and dataloaders in order to train our CNN model.\n",
    "    ###########################################################################\n",
    "\n",
    "    train_data = ASL_Dataset(X_train_comb, y_train_comb)\n",
    "    val_data   = ASL_Dataset(X_val_class, y_val_class)\n",
    "\n",
    "    batch_size = 200\n",
    "    n_epochs = 60\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "    val_loader = DataLoader(val_data, batch_size = 10, shuffle = False)\n",
    "    model = Network()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.7)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            outputs = model(imgs)  \n",
    "            loss = loss_fn(outputs, labels.long()) \n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item() \n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch, loss_train / len(train_loader)))\n",
    "\n",
    "    model.eval()       \n",
    "    validate(model, train_loader, val_loader)\n",
    "\n",
    "    ################## Running custom performance metrics #####################\n",
    "    X_2d = []\n",
    "    for i in X_val_class:\n",
    "        X_2d.append(i.reshape(1, 50, 50))\n",
    "    X_2d = np.array(X_2d)   \n",
    "    data = torch.FloatTensor(X_2d)       \n",
    "    labels = torch.LongTensor(y_val_class)\n",
    "    predictions = model(Variable(data))\n",
    "    performMetrics(predictions.data, labels, possibleLabels, \"CNN for Class test set\")\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRqzmVSCwNND"
   },
   "outputs": [],
   "source": [
    "X = np.load('train_data.npy')\n",
    "y = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YwJVL0YmwTXg",
    "outputId": "504b1f4a-9d10-4b4a-fa13-e3bad4b24ebb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-19 21:29:41.425176 Epoch 1, Training loss 2.192035213429877\n",
      "2020-04-19 21:31:10.435050 Epoch 10, Training loss 2.1949467557541866\n"
     ]
    }
   ],
   "source": [
    "train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6dijoQiDIhK"
   },
   "outputs": [],
   "source": [
    "def convert2DTo1D(arr):\n",
    "    if (len(arr) == 0):\n",
    "        return;\n",
    "    temp = np.array(arr[0]);\n",
    "    for i in range(1,len(arr)):\n",
    "        temp = np.append(temp, arr[i]);\n",
    "    return temp\n",
    "\n",
    "#Convert all the photos into 1D arrays\n",
    "def convertAllPhotosTo1DArrays(threeDArr):\n",
    "    if (len(threeDArr.shape) < 2):\n",
    "        print(\"Array size is not 3D\")\n",
    "        return threeDArr;\n",
    "    twoDArr = np.zeros(shape=(len(threeDArr),10000))\n",
    "    for i in range(len(threeDArr)):\n",
    "        twoDArr[i] = convert2DTo1D(threeDArr[i])\n",
    "    return twoDArr\n",
    "\n",
    "#Calculates the accuracy for each class\n",
    "def createAccuracyPerClassArray(y_actual, y_predict, labels):\n",
    "    correct = [0] * len(labels)\n",
    "    total = [0] * len(labels)\n",
    "    for i in range(len(y_actual)):\n",
    "        if y_actual[i] == y_predict[i]:\n",
    "            correct[labels.index(y_actual[i])] += 1\n",
    "        total[labels.index(y_actual[i])] += 1\n",
    "    accuracy = [0] * len(labels)\n",
    "    for i in range(len(correct)):\n",
    "        if (total[i] == 0):\n",
    "            accuracy[i] = 0\n",
    "        else:\n",
    "            accuracy[i] = correct[i] / total[i]\n",
    "    return accuracy\n",
    "\n",
    "def makeAccuracyGraph(arr, training, startingNum=0, title=\"\"):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(range(startingNum, startingNum + len(arr)),arr,color='blue', linestyle='dashed', marker=\"o\",\n",
    "            markerfacecolor='red', markersize=10, label=\"Test\")\n",
    "    plt.plot(range(startingNum, startingNum + len(arr)),arr,color='green', linestyle='-.', marker=\"o\",\n",
    "            markerfacecolor='purple', markersize=10, label=\"Training\")\n",
    "    plt.title(\"Accuracy vs\" + title)\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#Prints the perclass accuracy\n",
    "def printPerClassAccuracies(accuracy, labels, title=\"\"):\n",
    "      for i in range(len(accuracy)):\n",
    "        print(title, \" \", labels[i], \" accuracy: \", accuracy[i])\n",
    "    \n",
    "#Prints the overall accuracy and the per class accuracy for each N \n",
    "#(for example, if I were testing K different neighbors for KNN, the arr would be len(K), the perClass would be a 2D array with [K, len(labels)])\n",
    "def printAccuracies(arr, training, perClass, labels, startingNum = 0, title=\"\"):\n",
    "    for i in range(len(arr)):\n",
    "        print(title, \" - \", startingNum+i, \" overall accuracy: \", arr[i])\n",
    "        print(\"Per class accuracies for \", title, startingNum+i)\n",
    "        printPerClassAccuracies(perClass[i],labels)\n",
    "\n",
    "    makeAccuracyGraph(arr, training, startingNum, title)\n",
    "\n",
    "#Metrics function\n",
    "def performMetrics(y_te, y_pre, labels, name=\"\"):\n",
    "    y_test = [-1] * y_te.shape[0] #Create a N sized array, where N is the size of the training set\n",
    "    i_max = -1000\n",
    "    for i in range(len(y_te)):\n",
    "        i_max = -1\n",
    "        for j in range(len(y_te[i])): \n",
    "            if y_te[i][j] > i_max:\n",
    "                i_max = y_te[i][j]\n",
    "                y_test[i] = j\n",
    "      #JD6 We could easily just test here that if it is less than a threshold leave it at -1\n",
    "      #y_test[i] = j #if i_max < threshold\n",
    "\n",
    "    y_predict = y_pre.tolist()\n",
    "\n",
    "    #Converting them to be the letters\n",
    "    for i in range(len(y_predict)):\n",
    "        y_test[i] = labels[y_test[i]]\n",
    "        y_predict[i] = labels[y_predict[i]]\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        count += 1 if (y_test[i] == y_predict[i]) else 0\n",
    "    print(name, \" Overall average: \", (count/len(y_test)))\n",
    "\n",
    "    perClass = createAccuracyPerClassArray(y_test,y_predict,labels)\n",
    "    printPerClassAccuracies(perClass, labels, name)\n",
    "\n",
    "    #Confusion Maxtrix - Lecture 10\n",
    "    C = metrics.confusion_matrix(y_test,y_predict,labels=labels)\n",
    "    print(C)\n",
    "    C_scaled = list()\n",
    "    #Scaling each value\n",
    "    #JD6, may have to put an array of possible labels here?\n",
    "    for row in range(0,len(C)):\n",
    "        total = 0\n",
    "        C_scaled.append(list())\n",
    "        for col in range(0,len(C[row])):\n",
    "            total += C[row][col] \n",
    "        for col in range(0,len(C[row])):\n",
    "            C_scaled [row].append(C[row][col] / total) \n",
    "            #Divide each one to get the %\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(C_scaled, annot=True)\n",
    "\n",
    "    ax.set_title(\"Confusion matrix -\" + name)\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    plt.show()\n",
    "\n",
    "    #Taken from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    lw = 2\n",
    "    n_classes = len(labels)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        #From Dr. Silvia's OH\n",
    "        y_t = [True] * len(y_test)\n",
    "        y_p = [True] * len(y_test)\n",
    "        for j in range(len(y_test)):\n",
    "            y_t[j] = 1 if (y_test[j] == labels[i]) else 0\n",
    "            y_p[j] = 1 if (y_predict[j] == labels[i]) else 0\n",
    "        fpr[labels[i]], tpr[labels[i]], _ = metrics.roc_curve(y_t, y_p)\n",
    "        roc_auc[labels[i]] = metrics.auc(fpr[labels[i]], tpr[labels[i]])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[labels[i]] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[labels[i]], tpr[labels[i]])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "          label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                ''.format(roc_auc[\"macro\"]),\n",
    "          color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', \"y\", \"k\", \"g\", \"r\", \"m\", \"b\", \"c\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[labels[i]], tpr[labels[i]], color=color, lw=lw,\n",
    "              label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "              ''.format(labels[i], roc_auc[labels[i]]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve for each digit')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKPNMdMUPkbf"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
