{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO9kjEdrijYM",
        "colab_type": "code",
        "outputId": "9fad9cb3-c35d-4985-ccc2-7acb6cb60943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from skimage.color import rgb2gray\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import metrics\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "import datetime \n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io \n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from skimage import img_as_ubyte\n",
        "import os\n",
        "from skimage.util import random_noise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfWyMm64i6Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASL_Dataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "      \n",
        "        X_2d = []\n",
        "        for i in X:\n",
        "              X_2d.append(i.reshape(1, 50, 50))\n",
        "        X_2d = np.array(X_2d)\n",
        "    \n",
        "        # Convert data & labels from numpy to PyTorch format\n",
        "        data = torch.FloatTensor(X_2d)\n",
        "        #data = data.permute(0,3,1,2)        \n",
        "        labels = torch.LongTensor(y)        \n",
        "\n",
        "        # Store data as part of the class        \n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __len__(self):\n",
        "      \n",
        "        # Calculate and return the number of samples in the dataset\n",
        "        return(len(self.labels))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.data[idx], self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "921mDl_VldgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/justuser/sign-language-classifier-convnet-with-pytorch\n",
        " class Network(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(10, 15, 3) #15 or 20\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(15, 20, 3) #20 or 30\n",
        "        self.dropout1 = nn.Dropout2d()\n",
        "        \n",
        "        self.fc3 = nn.Linear(20 * 9 * 9, 270) \n",
        "        self.fc4 = nn.Linear(270, 9) \n",
        "        \n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "                \n",
        "        x = x.view(-1, 20 * 9 * 9) \n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        \n",
        "        return self.softmax(x)\n",
        "    \n",
        "    \n",
        "    def test(self, predictions, labels):\n",
        "        \n",
        "        self.eval()\n",
        "        correct = 0\n",
        "        for p, l in zip(predictions, labels):\n",
        "            if p == l:\n",
        "                correct += 1\n",
        "        \n",
        "        acc = correct / len(predictions)\n",
        "        print(\"Correct predictions: %5d / %5d (%5f)\" % (correct, len(predictions), acc))\n",
        "        \n",
        "    \n",
        "    def evaluate(self, predictions, labels):\n",
        "                \n",
        "        correct = 0\n",
        "        for p, l in zip(predictions, labels):\n",
        "            if p == l:\n",
        "                correct += 1\n",
        "        \n",
        "        acc = correct / len(predictions)\n",
        "        return(acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm2nRWK6eP9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     LoadMNIST()\n",
        "# Inputs:       N/A\n",
        "# Output:       X   - MNIST images\n",
        "#               y   - MNIST labels\n",
        "# Description:  This function loads the MNIST training and testing images. We \n",
        "#               will combine both sets in order to create one big dataset, and\n",
        "#               then reduce the size as to not overfit our model with the\n",
        "#               MNIST data. The images for letters C, G, H are different \n",
        "#               formats so we will discard of these images.\n",
        "###############################################################################\n",
        "\n",
        "def LoadMNIST():\n",
        "\n",
        "    # Load data\n",
        "    data_raw = pd.read_csv(\"drive/My Drive/sign_mnist_train.csv\")\n",
        "    test_data_raw = test = pd.read_csv(\"drive/My Drive/sign_mnist_test.csv\")\n",
        "\n",
        "    # Break up data and labels\n",
        "    labels = data_raw['label']\n",
        "    data_raw.drop('label', axis=1, inplace=True)\n",
        "    labels_test = test_data_raw['label']\n",
        "    test_data_raw.drop('label', axis=1, inplace=True)\n",
        "\n",
        "    # Normalize data\n",
        "    data_full = data_raw.values/255\n",
        "    labels_full = labels.values\n",
        "    test_data_full = test_data_raw.values/255 \n",
        "    labels_test_full = labels_test.values \n",
        "\n",
        "    # Concatenate training and test set\n",
        "    X_MNIST_full = np.concatenate((data_full, test_data_full))\n",
        "    y_MNIST_full = np.concatenate((labels_full, labels_test_full))\n",
        "\n",
        "    # Get rid of unused letters and the letters c, g, and h\n",
        "    X_MNIST = []\n",
        "    y_MNIST = []\n",
        "    for i in range(len(y_MNIST_full)):\n",
        "        if (y_MNIST_full[i] <= 8 and y_MNIST_full[i] != 2 and y_MNIST_full[i] != 6 and y_MNIST_full[i] != 7): #ADDED THE LAST AND STATEMENT TO GET RID OF I's\n",
        "            X_MNIST.append(X_MNIST_full[i])\n",
        "            y_MNIST.append(y_MNIST_full[i])\n",
        "    X_MNIST = np.asarray(X_MNIST)\n",
        "    y_MNIST = np.asarray(y_MNIST)\n",
        "\n",
        "    # Reshape data to 50x50\n",
        "    X_MNIST_50 = []\n",
        "    for i in range (len(X_MNIST)):\n",
        "        img_flat_orig = X_MNIST[i];\n",
        "        img_2d_orig = img_flat_orig.reshape(28, 28)\n",
        "        img_2d_new = cv2.resize(img_2d_orig, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
        "        img_1d_new = img_2d_new.flatten()\n",
        "        X_MNIST_50.append(img_1d_new)\n",
        "    X_MNIST_50 = np.asarray(X_MNIST_50)\n",
        "\n",
        "    # Store indices for each image and order them by letter\n",
        "    idx = np.ones((9,1457))*-1 \n",
        "    for i in range(len(y_MNIST)):\n",
        "        curr_let = y_MNIST[i]\n",
        "        curr_row = idx[curr_let]\n",
        "        unique_elements, counts_elements = np.unique(curr_row, return_counts=True)\n",
        "        next_idx = len(unique_elements) - 1\n",
        "        idx[curr_let][next_idx] = i\n",
        "\n",
        "    # Randomly choose N number of images for each letter\n",
        "    X_MNIST_reduced = []\n",
        "    y_MNIST_reduced = []\n",
        "    for i in range(idx.shape[0]):\n",
        "        if (i == 2 or i == 6 or i == 7):\n",
        "            continue\n",
        "        for j in range(700): # <----Change here to get reduced MNIST dataset size\n",
        "            ran_num = random.randint(0,idx.shape[1]-1)\n",
        "            while (idx[i][ran_num] == -1):\n",
        "                ran_num = random.randint(0,idx.shape[1]-1)\n",
        "            X_MNIST_reduced.append(X_MNIST_50[idx[i][ran_num].astype(int)])\n",
        "            y_MNIST_reduced.append(y_MNIST[idx[i][ran_num].astype(int)])\n",
        "    X_MNIST_reduced = np.asarray(X_MNIST_reduced)\n",
        "    y_MNIST_reduced = np.asarray(y_MNIST_reduced)\n",
        "\n",
        "    return X_MNIST_reduced, y_MNIST_reduced\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZivVmlA898",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     Multiple Data Augmentation Functions\n",
        "# Inputs:       N/A\n",
        "# Output:       N/A\n",
        "# Description:  These functions will perform a variety of data aumgentation \n",
        "#               functions, including rotation, flipping, adding noise, adding \n",
        "#               blur, and warp shifting.\n",
        "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
        "#               numpy-opencv-and-skimage-ef027e9898da\n",
        "###############################################################################\n",
        "def anticlockwise_rotation(image):\n",
        "    angle= random.randint(0,8)\n",
        "    return rotate(image, angle)\n",
        "\n",
        "def clockwise_rotation(image):\n",
        "    angle= random.randint(0,8)\n",
        "    return rotate(image, -angle)\n",
        "\n",
        "def h_flip(image):\n",
        "    return  np.fliplr(image)\n",
        "\n",
        "#def v_flip(image):\n",
        "    #return np.flipud(image)\n",
        "\n",
        "def add_noise(image):\n",
        "    return random_noise(image)\n",
        "\n",
        "def blur_image(image):\n",
        "    return cv2.GaussianBlur(img, (9,9),0)\n",
        "\n",
        "def warp_shift(image): \n",
        "    transform = AffineTransform(translation=(0,40)) \n",
        "    warp_image = warp(image, transform, mode=\"wrap\")\n",
        "    return warp_image\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-XSJvloM_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     CreateImages()\n",
        "# Inputs:       Letter - Chooses which letter to data augment\n",
        "#               X     - Input images\n",
        "#               y     - Output vectors\n",
        "# Output:       X_new - Data augmented images\n",
        "#               y_new - Data augmented labels\n",
        "# Description:  This function performs data augmentation for letters C, G, and \n",
        "#               H. It will also perform minor data augmentation for the whole\n",
        "#               dataset to increase the size and type of images we train our\n",
        "#               model with.\n",
        "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
        "#               numpy-opencv-and-skimage-ef027e9898da\n",
        "###############################################################################\n",
        "\n",
        "def CreateImages(letter, num_imgs, X, y):\n",
        "  \n",
        "    transformations = {'rotate anticlockwise': anticlockwise_rotation,\n",
        "                          'rotate clockwise': clockwise_rotation,\n",
        "                          'horizontal flip': h_flip, \n",
        "                          #'vertical flip': v_flip,\n",
        "                          'warp shift': warp_shift,\n",
        "                          'adding noise': add_noise}\n",
        "\n",
        "    index = []\n",
        "    if (letter == \"C\"):\n",
        "\n",
        "        # Find every index of C images\n",
        "        for i in range(len(y)):\n",
        "          if(y[i] == 2):\n",
        "            index.append(i)\n",
        "\n",
        "    elif (letter == \"G\"):\n",
        "\n",
        "        # Find every index of G images\n",
        "        for i in range(len(y)):\n",
        "          if(y[i] == 6):\n",
        "            index.append(i)\n",
        "\n",
        "    elif (letter == \"H\"):\n",
        "\n",
        "        # Find every index of H images\n",
        "        for i in range(len(y)):\n",
        "          if(y[i] == 7):\n",
        "            index.append(i)\n",
        "    else:\n",
        "\n",
        "        # Use all indices\n",
        "        for i in range(len(y)):\n",
        "            index.append(i)\n",
        "   \n",
        "    X_new = []\n",
        "    y_new = []\n",
        "\n",
        "    for i in range(1, num_imgs + 1):\n",
        "      idx = random.choice(index)\n",
        "      y_new.append(y[idx])\n",
        "      original_image = X[idx].reshape(50,50)\n",
        "      transformed_image=None\n",
        "      n = 0\n",
        "      transformation_count = random.randint(1, len(transformations))\n",
        "      while n <= transformation_count:\n",
        "          key = random.choice(list(transformations))\n",
        "          transformed_image = transformations[key](original_image)  \n",
        "          n = n + 1    \n",
        "      trans_img = transformed_image.flatten()\n",
        "      X_new.append(trans_img);\n",
        "\n",
        "    return X_new, y_new\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2FAZwqj4X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     DataAug()\n",
        "# Inputs:       X    - Input images\n",
        "#               y    - Output vectors\n",
        "# Output:       X_DA - Data augmented images\n",
        "#               y_DA - Data augmented labels\n",
        "# Description:  This function will use data augmentation to increase the size\n",
        "#               of our data and make our training set more proportional.\n",
        "# Link:         https://towardsdatascience.com/image-augmentation-using-python-\n",
        "#               numpy-opencv-and-skimage-ef027e9898da\n",
        "###############################################################################\n",
        "\n",
        "def DataAug(X, y):\n",
        "\n",
        "    ###################### Data Augmentation with C ###########################\n",
        "    # Create 800 more images of letter C \n",
        "    X_C, y_C = CreateImages(\"C\", 800, X, y)   \n",
        "\n",
        "    ###################### Data Augmentation with G ###########################\n",
        "    # Create 800 more images of letter G\n",
        "    X_G, y_G = CreateImages(\"G\", 800, X, y)\n",
        "\n",
        "    ###################### Data Augmentation with H ###########################\n",
        "    # Create 800 more images of letter H\n",
        "    X_H, y_H = CreateImages(\"H\", 800, X, y)\n",
        "      \n",
        "    ##################### Data Augmentation with All ##########################\n",
        "    # Create 1000 more images of all letters\n",
        "    X_all, y_all = CreateImages(\"All\", 1000, X, y)\n",
        "\n",
        "    X_DA = np.concatenate((X_C, X_G, X_H, X_all))\n",
        "    y_DA = np.concatenate((y_C, y_G, y_H, y_all))\n",
        "\n",
        "    return X_DA, y_DA\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1eYXu2LjRZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     training_loop()\n",
        "# Inputs:       n_epochs    - number of epochs\n",
        "#               optimizer   - optimizer function\n",
        "#               model       - model\n",
        "#               loss_fn     - loss function\n",
        "#               train_loader - training set dataloader\n",
        "# Output:       N/A\n",
        "# Description:  This function will perform the actual training of our\n",
        "#               designated model. Taken from Lecture 22 by Dr. Silva.\n",
        "###############################################################################\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  \n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader: \n",
        "            outputs = model(imgs)  \n",
        "            loss = loss_fn(outputs, labels.long()) \n",
        "\n",
        "            optimizer.zero_grad() \n",
        "            loss.backward() \n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item() \n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdCqlQKj27NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     validate()\n",
        "# Inputs:       model        - model\n",
        "#               train_loader - training set dataloader\n",
        "#               val_loader   - validation set dataloader\n",
        "# Output:       N/A\n",
        "# Description:  This function will perform the validation of our\n",
        "#               trained model. Taken from Lecture 22 by Dr. Silva.\n",
        "###############################################################################\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  \n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                total += labels.shape[0]  \n",
        "                correct += int((predicted == labels).sum()) \n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qCOMXSRWsyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "# Function:     train()\n",
        "# Inputs:       X - array of images in Nx100x100x3 format\n",
        "#               y - array of output charcters for images in Nx1 format \n",
        "# Output:       N/A\n",
        "# Description:  This function trains our CNN model with the dataset inputted \n",
        "#               through X and y. This fucntion will combine X and y with the\n",
        "#               MNIST hand gesture recognition dataset from Kaggle, to train \n",
        "#               a model compirsed of 3 convolutional layers and two linear\n",
        "#               layers, with dropout and maxpooling.\n",
        "###############################################################################\n",
        "\n",
        "def train(X, y):\n",
        "    ################# Section 1: Preprocessing/Splitting ######################\n",
        "    # Our preprocessing pipeline includes:\n",
        "    #          - Resizing image to 50x50\n",
        "    #          - Grayscaling image\n",
        "    #          - Flattening image to a 1D vecotr\n",
        "    #          - Converting labels from characters to numbers\n",
        "    # We resize the image to half its original size to limit the amount of \n",
        "    # features inputted in to our model. Grayscaling also diminshes the images \n",
        "    # to only 1 channel and will normalizes our values between 0 and 1 for us. \n",
        "    # We flatten the image to 1D in order to more easily combine it with our \n",
        "    # other dataset. We will als split this data into training and validation \n",
        "    # since we will want to run a test on just this data to see how our model \n",
        "    # performs.\n",
        "    ###########################################################################\n",
        "    # Preprocessing\n",
        "    X_norm = []\n",
        "    for i in range(X.shape[0]):\n",
        "        img = X[i]\n",
        "        img_r = cv2.resize(img, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
        "        img_g = rgb2gray(img_r)\n",
        "        img_1d = img_g.flatten()\n",
        "        X_norm.append(img_1d)\n",
        "    X_norm = np.asarray(X_norm)\n",
        "\n",
        "    # Convert characters to numbers\n",
        "    y = np.squeeze(y)\n",
        "    ulabels = np.unique(y)\n",
        "    y_num = np.zeros(len(y))\n",
        "    for i in range(len(ulabels)):\n",
        "        y_num[y == ulabels[i]] = i\n",
        "\n",
        "    # Splitting\n",
        "    X_train_class, X_val_class, y_train_class, y_val_class = train_test_split(\n",
        "          X_norm, y_num, test_size = 0.35, random_state = 4) \n",
        "\n",
        "    ################## Section 2: Loading Other Dataset #######################\n",
        "    # We will now add our addition MNIST dataset from Kaggle. The images come \n",
        "    # in as Nx784 array, which is N 28x28 images flattened. \n",
        "    # Link: https://www.kaggle.com/datamunge/sign-language-mnist\n",
        "    ###########################################################################\n",
        "\n",
        "    X_MNIST, y_MNIST = LoadMNIST()\n",
        "\n",
        "    X_train_MNIST, X_val_MNIST, y_train_MNIST, y_val_MNIST = train_test_split(\n",
        "          X_MNIST, y_MNIST, test_size = 0.2, random_state = 4) \n",
        "\n",
        "    ##################### Section 3: Combining Datasets #######################\n",
        "    # We will now combine datasets to get our total training and validation \n",
        "    # sets.\n",
        "    ###########################################################################\n",
        "\n",
        "    X_train_comb = np.concatenate((X_train_class, X_train_MNIST))\n",
        "    y_train_comb = np.concatenate((y_train_class, y_train_MNIST))\n",
        "    X_val_comb = np.concatenate((X_val_class, X_val_MNIST))\n",
        "    y_val_comb = np.concatenate((y_val_class, y_val_MNIST))\n",
        "\n",
        "    ##################### Section 4: Data Augmentation ########################\n",
        "    # We will see that when we combine our class data and our MNIST data, we \n",
        "    # have a unproportional amount for each letter. Namely, we don't have any \n",
        "    # C, G and H data from MNIST. Here, we will use data augmentation to \n",
        "    # increase the size for these letters, and to also add more images for\n",
        "    # every letter.\n",
        "    ###########################################################################\n",
        "\n",
        "    X_DA, y_DA = DataAug(X_train_comb, y_train_comb)\n",
        "\n",
        "    X_train_comb = np.concatenate((X_train_comb, X_DA))\n",
        "    y_train_comb = np.concatenate((y_train_comb, y_DA))\n",
        "\n",
        "    # Print the spread of our training data\n",
        "    plt.figure(figsize = (10,5))\n",
        "    sns.countplot(x = y_train_comb);\n",
        "\n",
        "    ######################## Section 5: Training ##############################\n",
        "    # We will now train our model with our combined training dataset. We are \n",
        "    # a custom dataset and dataloaders in order to train our CNN model.\n",
        "    ###########################################################################\n",
        "\n",
        "    train_data = ASL_Dataset(X_train_comb, y_train_comb)\n",
        "    val_data   = ASL_Dataset(X_val_comb, y_val_comb)\n",
        "\n",
        "    batch_size = 200\n",
        "    n_epochs = 60\n",
        "    learning_rate = 0.08\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "    val_loader = DataLoader(val_data, batch_size = batch_size, shuffle = False)\n",
        "    model = Network()\n",
        "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.7)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    training_loop(n_epochs = 60, optimizer = optimizer, model = model,\n",
        "                    loss_fn = loss_fn, train_loader = train_loader)\n",
        "    \n",
        "    ####################### Section 6: Validation #############################\n",
        "    # We will now validate our model to see how well it is trained, and look\n",
        "    # our for overfitting.\n",
        "    ###########################################################################\n",
        "\n",
        "    return model, train_loader, val_loader\n",
        "    \n",
        "    #validate(model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRqzmVSCwNND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.load('drive/My Drive/train_data.npy')\n",
        "y = np.load('drive/My Drive/train_labels.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwJVL0YmwTXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "79b60b98-0798-4d3c-bab6-bc83586a4358"
      },
      "source": [
        "model, train_loader, val_loader = train(X,y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-19 19:36:43.513718 Epoch 1, Training loss 2.193614661693573\n",
            "2020-04-19 19:37:38.190455 Epoch 10, Training loss 0.4146093040704727\n",
            "2020-04-19 19:38:39.083877 Epoch 20, Training loss 0.16570645421743393\n",
            "2020-04-19 19:39:39.655950 Epoch 30, Training loss 0.10031182183884084\n",
            "2020-04-19 19:40:40.684339 Epoch 40, Training loss 0.07379881450906396\n",
            "2020-04-19 19:41:41.182278 Epoch 50, Training loss 0.05747241200879216\n",
            "2020-04-19 19:42:41.836199 Epoch 60, Training loss 0.045160958427004516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJdshkP5cdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be03aabd-be83-465d-9d91-43b50916eaf9"
      },
      "source": [
        " validate(model, train_loader, val_loader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.98\n",
            "Accuracy val: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}